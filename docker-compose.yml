services:
  taskbroker:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - 'taskbroker-data:/opt/'
    ports:
    - "50051:50051"
    depends_on:
      - kafka
  kafka:
    image: 'ghcr.io/getsentry/image-mirror-confluentinc-cp-kafka:7.5.0'
    container_name: taskbroker_kafka
    environment:
      # https://docs.confluent.io/platform/current/installation/docker/config-reference.html#cp-kakfa-example
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@127.0.0.1:29093'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_NODE_ID: '1'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_LISTENERS: 'PLAINTEXT://0.0.0.0:29092,INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://127.0.0.1:29092,INTERNAL://kafka:9093,EXTERNAL://127.0.0.1:9092'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: '1'
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: '1'
      KAFKA_LOG_RETENTION_HOURS: '24'
      KAFKA_MESSAGE_MAX_BYTES: '50000000' #50MB or bust
      KAFKA_MAX_REQUEST_SIZE: '50000000' #50MB on requests apparently too
    volumes:
      - 'taskbroker-kafka:/var/lib/kafka/data'
      - 'taskbroker-kafka-log:/var/lib/kafka/log'
    healthcheck:
      test: ['CMD-SHELL', 'nc -z localhost 9092']
      interval: 10s
      timeout: 10s
      retries: 30
    ports:
      - '9092:9092'
      - '9093:9093'
    networks:
      - taskbroker
    extra_hosts:
      host.docker.internal: host-gateway

volumes:
  # These store application data that should persist across restarts.
  taskbroker-kafka:
  taskbroker-data:
  taskbroker-kafka-log:

networks:
  taskbroker:
    name: taskbroker
